{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e311c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing problem 1/500...\n",
      "Processing problem 2/500...\n",
      "Processing problem 3/500...\n",
      "Processing problem 4/500...\n",
      "Processing problem 5/500...\n",
      "Processing problem 6/500...\n",
      "Processing problem 7/500...\n",
      "Processing problem 8/500...\n",
      "Processing problem 9/500...\n",
      "Processing problem 10/500...\n",
      "Processing problem 11/500...\n",
      "Processing problem 12/500...\n",
      "Processing problem 13/500...\n",
      "Processing problem 14/500...\n",
      "Processing problem 15/500...\n",
      "Processing problem 16/500...\n",
      "Processing problem 17/500...\n",
      "Processing problem 18/500...\n",
      "Processing problem 19/500...\n",
      "Processing problem 20/500...\n",
      "Processing problem 21/500...\n",
      "Processing problem 22/500...\n",
      "Processing problem 23/500...\n",
      "Processing problem 24/500...\n",
      "Processing problem 25/500...\n",
      "Processing problem 26/500...\n",
      "Processing problem 27/500...\n",
      "Processing problem 28/500...\n",
      "Processing problem 29/500...\n",
      "Processing problem 30/500...\n",
      "Processing problem 31/500...\n",
      "Processing problem 32/500...\n",
      "Processing problem 33/500...\n",
      "Processing problem 34/500...\n",
      "Processing problem 35/500...\n",
      "Processing problem 36/500...\n",
      "Processing problem 37/500...\n",
      "Processing problem 38/500...\n",
      "Processing problem 39/500...\n",
      "Processing problem 40/500...\n",
      "Processing problem 41/500...\n",
      "Processing problem 42/500...\n",
      "Processing problem 43/500...\n",
      "Processing problem 44/500...\n",
      "Processing problem 45/500...\n",
      "Processing problem 46/500...\n",
      "Processing problem 47/500...\n",
      "Processing problem 48/500...\n",
      "Processing problem 49/500...\n",
      "Processing problem 50/500...\n",
      "Processing problem 51/500...\n",
      "Processing problem 52/500...\n",
      "Processing problem 53/500...\n",
      "Processing problem 54/500...\n",
      "Processing problem 55/500...\n",
      "Processing problem 56/500...\n",
      "Processing problem 57/500...\n",
      "Processing problem 58/500...\n",
      "Processing problem 59/500...\n",
      "Processing problem 60/500...\n",
      "Processing problem 61/500...\n",
      "Processing problem 62/500...\n",
      "Processing problem 63/500...\n",
      "Processing problem 64/500...\n",
      "Processing problem 65/500...\n",
      "Processing problem 66/500...\n",
      "Processing problem 67/500...\n",
      "Processing problem 68/500...\n",
      "Processing problem 69/500...\n",
      "Processing problem 70/500...\n",
      "Processing problem 71/500...\n",
      "Processing problem 72/500...\n",
      "Processing problem 73/500...\n",
      "Processing problem 74/500...\n",
      "Processing problem 75/500...\n",
      "Processing problem 76/500...\n",
      "Processing problem 77/500...\n",
      "Processing problem 78/500...\n",
      "Processing problem 79/500...\n",
      "Processing problem 80/500...\n",
      "Processing problem 81/500...\n",
      "Processing problem 82/500...\n",
      "Processing problem 83/500...\n",
      "Processing problem 84/500...\n",
      "Processing problem 85/500...\n",
      "Processing problem 86/500...\n",
      "Processing problem 87/500...\n",
      "Processing problem 88/500...\n",
      "Processing problem 89/500...\n",
      "Processing problem 90/500...\n",
      "Processing problem 91/500...\n",
      "Processing problem 92/500...\n",
      "Processing problem 93/500...\n",
      "Processing problem 94/500...\n",
      "Processing problem 95/500...\n",
      "Processing problem 96/500...\n",
      "Processing problem 97/500...\n",
      "Processing problem 98/500...\n",
      "Processing problem 99/500...\n",
      "Processing problem 100/500...\n",
      "Processing problem 101/500...\n",
      "Processing problem 102/500...\n",
      "Processing problem 103/500...\n",
      "Processing problem 104/500...\n",
      "Processing problem 105/500...\n",
      "Processing problem 106/500...\n",
      "Processing problem 107/500...\n",
      "Processing problem 108/500...\n",
      "Processing problem 109/500...\n",
      "Processing problem 110/500...\n",
      "Processing problem 111/500...\n",
      "Processing problem 112/500...\n",
      "Processing problem 113/500...\n",
      "Processing problem 114/500...\n",
      "Processing problem 115/500...\n",
      "Processing problem 116/500...\n",
      "Processing problem 117/500...\n",
      "Processing problem 118/500...\n",
      "Processing problem 119/500...\n",
      "Processing problem 120/500...\n",
      "Processing problem 121/500...\n",
      "Processing problem 122/500...\n",
      "Processing problem 123/500...\n",
      "Processing problem 124/500...\n",
      "Processing problem 125/500...\n",
      "Processing problem 126/500...\n",
      "Processing problem 127/500...\n",
      "Processing problem 128/500...\n",
      "Processing problem 129/500...\n",
      "Processing problem 130/500...\n",
      "Processing problem 131/500...\n",
      "Processing problem 132/500...\n",
      "Processing problem 133/500...\n",
      "Processing problem 134/500...\n",
      "Processing problem 135/500...\n",
      "Processing problem 136/500...\n",
      "Processing problem 137/500...\n",
      "Processing problem 138/500...\n",
      "Processing problem 139/500...\n",
      "Processing problem 140/500...\n",
      "Processing problem 141/500...\n",
      "Processing problem 142/500...\n",
      "Processing problem 143/500...\n",
      "Processing problem 144/500...\n",
      "Processing problem 145/500...\n",
      "Processing problem 146/500...\n",
      "Processing problem 147/500...\n",
      "Processing problem 148/500...\n",
      "Processing problem 149/500...\n",
      "Processing problem 150/500...\n",
      "Processing problem 151/500...\n",
      "Processing problem 152/500...\n",
      "Processing problem 153/500...\n",
      "Processing problem 154/500...\n",
      "Processing problem 155/500...\n",
      "Processing problem 156/500...\n",
      "Processing problem 157/500...\n",
      "Processing problem 158/500...\n",
      "Processing problem 159/500...\n",
      "Processing problem 160/500...\n",
      "Processing problem 161/500...\n",
      "Processing problem 162/500...\n",
      "Processing problem 163/500...\n",
      "Processing problem 164/500...\n",
      "Processing problem 165/500...\n",
      "Processing problem 166/500...\n",
      "Processing problem 167/500...\n",
      "Processing problem 168/500...\n",
      "Processing problem 169/500...\n",
      "Processing problem 170/500...\n",
      "Processing problem 171/500...\n",
      "Processing problem 172/500...\n",
      "Processing problem 173/500...\n",
      "Processing problem 174/500...\n",
      "Processing problem 175/500...\n",
      "Processing problem 176/500...\n",
      "Processing problem 177/500...\n",
      "Processing problem 178/500...\n",
      "Processing problem 179/500...\n",
      "Processing problem 180/500...\n",
      "Processing problem 181/500...\n",
      "Processing problem 182/500...\n",
      "Processing problem 183/500...\n",
      "Processing problem 184/500...\n",
      "Processing problem 185/500...\n",
      "Processing problem 186/500...\n",
      "Processing problem 187/500...\n",
      "Processing problem 188/500...\n",
      "Processing problem 189/500...\n",
      "Processing problem 190/500...\n",
      "Processing problem 191/500...\n",
      "Processing problem 192/500...\n",
      "Processing problem 193/500...\n",
      "Processing problem 194/500...\n",
      "Processing problem 195/500...\n",
      "Processing problem 196/500...\n",
      "Processing problem 197/500...\n",
      "Processing problem 198/500...\n",
      "Processing problem 199/500...\n",
      "Processing problem 200/500...\n",
      "Processing problem 201/500...\n",
      "Processing problem 202/500...\n",
      "Processing problem 203/500...\n",
      "Processing problem 204/500...\n",
      "Processing problem 205/500...\n",
      "Processing problem 206/500...\n",
      "Processing problem 207/500...\n",
      "Processing problem 208/500...\n",
      "Processing problem 209/500...\n",
      "Processing problem 210/500...\n",
      "Processing problem 211/500...\n",
      "Processing problem 212/500...\n",
      "Processing problem 213/500...\n",
      "Processing problem 214/500...\n",
      "Processing problem 215/500...\n",
      "Processing problem 216/500...\n",
      "Processing problem 217/500...\n",
      "Processing problem 218/500...\n",
      "Processing problem 219/500...\n",
      "Processing problem 220/500...\n",
      "Processing problem 221/500...\n",
      "Processing problem 222/500...\n",
      "Processing problem 223/500...\n",
      "Processing problem 224/500...\n",
      "Processing problem 225/500...\n",
      "Processing problem 226/500...\n",
      "Processing problem 227/500...\n",
      "Processing problem 228/500...\n",
      "Processing problem 229/500...\n",
      "Processing problem 230/500...\n",
      "Processing problem 231/500...\n",
      "Processing problem 232/500...\n",
      "Processing problem 233/500...\n",
      "Processing problem 234/500...\n",
      "Processing problem 235/500...\n",
      "Processing problem 236/500...\n",
      "Processing problem 237/500...\n",
      "Processing problem 238/500...\n",
      "Processing problem 239/500...\n",
      "Processing problem 240/500...\n",
      "Processing problem 241/500...\n",
      "Processing problem 242/500...\n",
      "Processing problem 243/500...\n",
      "Processing problem 244/500...\n",
      "Processing problem 245/500...\n",
      "Processing problem 246/500...\n",
      "Processing problem 247/500...\n",
      "Processing problem 248/500...\n",
      "Processing problem 249/500...\n",
      "Processing problem 250/500...\n",
      "Processing problem 251/500...\n",
      "Processing problem 252/500...\n",
      "Processing problem 253/500...\n",
      "Processing problem 254/500...\n",
      "Processing problem 255/500...\n",
      "Processing problem 256/500...\n",
      "Processing problem 257/500...\n",
      "Processing problem 258/500...\n",
      "Processing problem 259/500...\n",
      "Processing problem 260/500...\n",
      "Processing problem 261/500...\n",
      "Processing problem 262/500...\n",
      "Processing problem 263/500...\n",
      "Processing problem 264/500...\n",
      "Processing problem 265/500...\n",
      "Processing problem 266/500...\n",
      "Processing problem 267/500...\n",
      "Processing problem 268/500...\n",
      "Processing problem 269/500...\n",
      "Processing problem 270/500...\n",
      "Processing problem 271/500...\n",
      "Processing problem 272/500...\n",
      "Processing problem 273/500...\n",
      "Processing problem 274/500...\n",
      "Processing problem 275/500...\n",
      "Processing problem 276/500...\n",
      "Processing problem 277/500...\n",
      "Processing problem 278/500...\n",
      "Processing problem 279/500...\n",
      "Processing problem 280/500...\n",
      "Processing problem 281/500...\n",
      "Processing problem 282/500...\n",
      "Processing problem 283/500...\n",
      "Processing problem 284/500...\n",
      "Processing problem 285/500...\n",
      "Processing problem 286/500...\n",
      "Processing problem 287/500...\n",
      "Processing problem 288/500...\n",
      "Processing problem 289/500...\n",
      "Processing problem 290/500...\n",
      "Processing problem 291/500...\n",
      "Processing problem 292/500...\n",
      "Processing problem 293/500...\n",
      "Processing problem 294/500...\n",
      "Processing problem 295/500...\n",
      "Processing problem 296/500...\n",
      "Processing problem 297/500...\n",
      "Processing problem 298/500...\n",
      "Processing problem 299/500...\n",
      "Processing problem 300/500...\n",
      "Processing problem 301/500...\n",
      "Processing problem 302/500...\n",
      "Processing problem 303/500...\n",
      "Processing problem 304/500...\n",
      "Processing problem 305/500...\n",
      "Processing problem 306/500...\n",
      "Processing problem 307/500...\n",
      "Processing problem 308/500...\n",
      "Processing problem 309/500...\n",
      "Processing problem 310/500...\n",
      "Processing problem 311/500...\n",
      "Processing problem 312/500...\n",
      "Processing problem 313/500...\n",
      "Processing problem 314/500...\n",
      "Processing problem 315/500...\n",
      "Processing problem 316/500...\n",
      "Processing problem 317/500...\n",
      "Processing problem 318/500...\n",
      "Processing problem 319/500...\n",
      "Processing problem 320/500...\n",
      "Processing problem 321/500...\n",
      "Processing problem 322/500...\n",
      "Processing problem 323/500...\n",
      "Processing problem 324/500...\n",
      "Processing problem 325/500...\n",
      "Processing problem 326/500...\n",
      "Processing problem 327/500...\n",
      "Processing problem 328/500...\n",
      "Processing problem 329/500...\n",
      "Processing problem 330/500...\n",
      "Processing problem 331/500...\n",
      "Processing problem 332/500...\n",
      "Processing problem 333/500...\n",
      "Processing problem 334/500...\n",
      "Processing problem 335/500...\n",
      "Processing problem 336/500...\n",
      "Processing problem 337/500...\n",
      "Processing problem 338/500...\n",
      "Processing problem 339/500...\n",
      "Processing problem 340/500...\n",
      "Processing problem 341/500...\n",
      "Processing problem 342/500...\n",
      "Processing problem 343/500...\n",
      "Processing problem 344/500...\n",
      "Processing problem 345/500...\n",
      "Processing problem 346/500...\n",
      "Processing problem 347/500...\n",
      "Processing problem 348/500...\n",
      "Processing problem 349/500...\n",
      "Processing problem 350/500...\n",
      "Processing problem 351/500...\n",
      "Processing problem 352/500...\n",
      "Processing problem 353/500...\n",
      "Processing problem 354/500...\n",
      "Processing problem 355/500...\n",
      "Processing problem 356/500...\n",
      "Processing problem 357/500...\n",
      "Processing problem 358/500...\n",
      "Processing problem 359/500...\n",
      "Processing problem 360/500...\n",
      "Processing problem 361/500...\n",
      "Processing problem 362/500...\n",
      "Processing problem 363/500...\n",
      "Processing problem 364/500...\n",
      "Processing problem 365/500...\n",
      "Processing problem 366/500...\n",
      "Processing problem 367/500...\n",
      "Processing problem 368/500...\n",
      "Processing problem 369/500...\n",
      "Processing problem 370/500...\n",
      "Processing problem 371/500...\n",
      "Processing problem 372/500...\n",
      "Processing problem 373/500...\n",
      "Processing problem 374/500...\n",
      "Processing problem 375/500...\n",
      "Processing problem 376/500...\n",
      "Processing problem 377/500...\n",
      "Processing problem 378/500...\n",
      "Processing problem 379/500...\n",
      "Processing problem 380/500...\n",
      "Processing problem 381/500...\n",
      "Processing problem 382/500...\n",
      "Processing problem 383/500...\n",
      "Processing problem 384/500...\n",
      "Processing problem 385/500...\n",
      "Processing problem 386/500...\n",
      "Processing problem 387/500...\n",
      "Processing problem 388/500...\n",
      "Processing problem 389/500...\n",
      "Processing problem 390/500...\n",
      "Processing problem 391/500...\n",
      "Processing problem 392/500...\n",
      "Processing problem 393/500...\n",
      "Processing problem 394/500...\n",
      "Processing problem 395/500...\n",
      "Processing problem 396/500...\n",
      "Processing problem 397/500...\n",
      "Processing problem 398/500...\n",
      "Processing problem 399/500...\n",
      "Processing problem 400/500...\n",
      "Processing problem 401/500...\n",
      "Processing problem 402/500...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(problems):\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing problem \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_PROBLEMS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     kl_curve = \u001b[43mkl_per_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     all_curves.append(kl_curve)\n\u001b[32m     62\u001b[39m max_len = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m all_curves)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mkl_per_prompt\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     37\u001b[39m inputs = tokenizer(\n\u001b[32m     38\u001b[39m     text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, max_length=MAX_LENGTH\n\u001b[32m     39\u001b[39m ).to(DEVICE)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     final_logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m.logits.detach().cpu()\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[32m     45\u001b[39m     h.remove()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m output_hidden_states = (\n\u001b[32m    819\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    820\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/transformers/utils/generic.py:965\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    967\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    537\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    538\u001b[39m         partial(decoder_layer.\u001b[34m__call__\u001b[39m, **flash_attn_kwargs),\n\u001b[32m    539\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    546\u001b[39m         position_embeddings,\n\u001b[32m    547\u001b[39m     )\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1879\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1876\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1878\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1880\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1881\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1882\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1883\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1884\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/dl/lib/python3.13/site-packages/torch/nn/modules/module.py:1840\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1838\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1839\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1843\u001b[39m     result = hook_result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mkl_per_prompt.<locals>.make_hook.<locals>.hook\u001b[39m\u001b[34m(module, inputs, outputs)\u001b[39m\n\u001b[32m     30\u001b[39m hidden = model.model.norm(hidden)\n\u001b[32m     31\u001b[39m logits = hidden @ model.lm_head.weight.T\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m layer_logits.append(\u001b[43mlogits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "N_PROBLEMS = 500\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-Math-1.5B\"\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "DTYPE = torch.float32\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "ds = load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test[:{}]\".format(N_PROBLEMS))\n",
    "problems = [f\"Q: {item['problem']} A:\" for item in ds]\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=DTYPE, device_map=None\n",
    ").to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "# --- Single-prompt KL computation ---\n",
    "def kl_per_prompt(text):\n",
    "    layer_logits = []\n",
    "\n",
    "    def make_hook():\n",
    "        def hook(module, inputs, outputs):\n",
    "            hidden = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "            hidden = model.model.norm(hidden)\n",
    "            logits = hidden @ model.lm_head.weight.T\n",
    "            layer_logits.append(logits.detach().cpu())\n",
    "        return hook\n",
    "\n",
    "    hooks = [blk.register_forward_hook(make_hook()) for blk in model.model.layers]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        final_logits = model(**inputs).logits.detach().cpu()\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    kl_scores = []\n",
    "    for logits in layer_logits:\n",
    "        q = F.log_softmax(logits[:, -1, :], dim=-1)\n",
    "        p = F.softmax(final_logits[:, -1, :], dim=-1)\n",
    "        kl = F.kl_div(q, p, reduction=\"batchmean\")\n",
    "        kl_scores.append(kl.item())\n",
    "\n",
    "    return kl_scores\n",
    "\n",
    "all_curves = []\n",
    "for i, prompt in enumerate(problems):\n",
    "    print(f\"Processing problem {i+1}/{N_PROBLEMS}...\")\n",
    "    kl_curve = kl_per_prompt(prompt)\n",
    "    all_curves.append(kl_curve)\n",
    "\n",
    "max_len = max(len(c) for c in all_curves)\n",
    "arr = np.array([\n",
    "    np.pad(c, (0, max_len - len(c)), constant_values=np.nan)\n",
    "    for c in all_curves\n",
    "])\n",
    "mean_curve = np.nanmean(arr, axis=0)\n",
    "std_curve = np.nanstd(arr, axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "x = np.arange(len(mean_curve), step=1)\n",
    "plt.plot(x, mean_curve, color=\"blue\", label=\"Mean KL-Divergence\")\n",
    "plt.fill_between(\n",
    "    x, mean_curve - std_curve, mean_curve + std_curve,\n",
    "    color=\"blue\", alpha=0.2, label=\"±1 Std\"\n",
    ")\n",
    "plt.title(f\"{MODEL_NAME} – Average LogitLens KL vs Layer ({N_PROBLEMS} MATH-500 Problems)\")\n",
    "plt.xlabel(\"Layer index\")\n",
    "plt.ylabel(\"Average KL Divergence to Final Logits\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(x)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed0b2d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
