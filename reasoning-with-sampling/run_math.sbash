#!/bin/bash --login
#SBATCH --job-name=trunc_ps_math_hf
#SBATCH --partition=gpunodes
#SBATCH -t 0-23:59
#SBATCH -c 4
#SBATCH --mem=24GB
#SBATCH --gres=gpu:rtx_a4000:1
#SBATCH --output=slurm_jobs/%a.out
#SBATCH --error=slurm_jobs/%a.err
#SBATCH --mail-user=khashayar1924@gmail.com
#SBATCH --mail-type=ALL

# --- Configuration ---
# Layer range: layers 20-27 (8 layers)
# Each array task handles one layer and loops through all batches
LAYER_START=20
LAYER_END=27
SEED=42

# --- map array id -> layer_idx ---
# Array 0-7 maps to layers 20-27
LAYER_IDX=20

# Hugging Face repo configuration
HF_REPO_BASE="khashazad/Qwen_Qwen2.5-Math-1.5B-truncated"
MODEL_NAME="Qwen_Qwen2.5-Math-1.5B"
KEEP_LAST_LAYER=true # Set to false for no-last variants

# Generate model name for path (replace / with _)
MODEL_NAME_PATH=$(echo "$MODEL_NAME" | tr '/' '_')

# --- 1. Setup Paths ---
# Get the first available scratch directory
SCRATCH_ROOT=$(ls -d /scratch/scratch-space/expires-* | head -n 1)

RESULT_DIR="$HOME/truncated-transformer-reasoning/reasoning-with-sampling/results"
mkdir -p "$RESULT_DIR"

# Generate the full HF model path dynamically
SUFFIX="keeplast"
if [ "$KEEP_LAST_LAYER" != true ]; then
    SUFFIX="no-last"
fi
HF_MODEL_PATH="${HF_REPO_BASE}/${MODEL_NAME_PATH}/layer${LAYER_IDX}_${SUFFIX}"

echo ">>> CONFIGURATION <<<"
echo "Running in: $(pwd)"
echo "Repository root: $REPO_ROOT"
echo "Temporary Scratch: $SCRATCH_ROOT"
echo "Results Directory: $RESULTS_DIR"
echo "Layer Index: ${LAYER_IDX}"
echo "HF Model Path: ${HF_MODEL_PATH}"
echo "Keep Last Layer: ${KEEP_LAST_LAYER}"

# --- 2. Environment Setup (In Scratch) ---
ENV_PATH="$SCRATCH_ROOT/$USER/math_run_env"

# Create environment if it doesn't exist (Self-Healing)
if [ ! -d "$ENV_PATH" ]; then
    echo "Creating virtual environment in scratch: $ENV_PATH"
    python3 -m venv "$ENV_PATH"
    source "$ENV_PATH/bin/activate"
    pip install --upgrade pip

    # INSTALLS: Mapping your imports to pip packages
    # torch, matplotlib, numpy, transformers, datasets, accelerate
    pip install torch transformers pandas tqdm accelerate datasets huggingface_hub
else
    echo "Activating existing environment: $ENV_PATH"
    source "$ENV_PATH/bin/activate"

    pip install torch transformers pandas tqdm accelerate datasets huggingface_hub

    # Optional: Ensure packages are present even in existing env
    # pip install --upgrade torch transformers datasets matplotlib numpy accelerate
fi

# --- 3. Set Model Cache (In Scratch) ---
echo "Setting Hugging Face cache location..."
export HF_HOME="$SCRATCH_ROOT/$USER/hf_cache"
mkdir -p "$HF_HOME"

# Loop through all batches for this layer
# Using the exported PYTHON_EXEC path guarantees we use the Python with installed packages
# Use 'time' to measure execution time for this batch (optional but useful)
python run_math.py \
    --mcmc_steps=10 \
    --temperature=0.25 \
    --seed="${SEED}" \
    --model="${MODEL_NAME}" \
    --layer_idx="${LAYER_IDX}" \
    --hf_model_path="${HF_MODEL_PATH}" \
    --keep_last_layer \
    --save_str="${RESULTS_DIR}"

echo ">>> JOB COMPLETE for Layer ${LAYER_IDX} <<<"
